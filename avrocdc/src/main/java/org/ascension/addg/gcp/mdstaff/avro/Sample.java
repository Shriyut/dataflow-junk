package org.ascension.addg.gcp.mdstaff.avro;

import org.apache.beam.sdk.Pipeline;
import org.apache.beam.sdk.coders.AvroCoder;
import org.apache.beam.sdk.io.AvroIO;
import org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO;
import org.apache.beam.sdk.options.PipelineOptionsFactory;
import org.apache.beam.sdk.transforms.Create;
import org.apache.beam.sdk.transforms.DoFn;
import org.apache.beam.sdk.transforms.MapElements;
import org.apache.beam.sdk.transforms.ParDo;
import org.apache.beam.sdk.transforms.SimpleFunction;
import org.apache.beam.sdk.values.KV;
import org.apache.beam.sdk.values.PCollection;
import org.apache.beam.sdk.values.TypeDescriptor;
import org.ascension.addg.gcp.mdstaff.avro.SampleIngestionOptions;
import org.json.simple.JSONObject;

import com.google.api.services.bigquery.model.TableFieldSchema;
import com.google.api.services.bigquery.model.TableRow;
import com.google.api.services.bigquery.model.TableSchema;
import com.google.cloud.bigquery.JobInfo.CreateDisposition;
import com.google.cloud.bigquery.JobInfo.WriteDisposition;
import com.google.common.collect.ImmutableList;

import tech.allegro.schema.json2avro.converter.JsonAvroConverter;

import java.util.List;

import org.apache.avro.Schema;
import org.apache.avro.generic.GenericData;
import org.apache.avro.generic.GenericData.Record;
import org.apache.avro.generic.GenericRecord;

public class Sample {

	public static void main(String[] args) {
		
		SampleIngestionOptions options =  PipelineOptionsFactory.fromArgs(args).withValidation().as(SampleIngestionOptions.class);
		Pipeline pipeline= Pipeline.create(options);
		
		String schemaStr = "{\r\n"
				+ "  \"type\" : \"record\",\r\n"
				+ "  \"name\" : \"kylosample\",\r\n"
				+ "  \"doc\" : \"Schema generated by Kite\",\r\n"
				+ "  \"fields\" : [ {\r\n"
				+ "    \"name\" : \"registration_dttm\",\r\n"
				+ "    \"type\" : \"string\",\r\n"
				+ "    \"doc\" : \"Type inferred from '2016-02-03T07:55:29Z'\"\r\n"
				+ "  }, {\r\n"
				+ "    \"name\" : \"id\",\r\n"
				+ "    \"type\" : \"string\",\r\n"
				+ "    \"doc\" : \"Type inferred from '1'\"\r\n"
				+ "  }, {\r\n"
				+ "    \"name\" : \"first_name\",\r\n"
				+ "    \"type\" : \"string\",\r\n"
				+ "    \"doc\" : \"Type inferred from 'Amanda'\"\r\n"
				+ "  }, {\r\n"
				+ "    \"name\" : \"last_name\",\r\n"
				+ "    \"type\" : \"string\",\r\n"
				+ "    \"doc\" : \"Type inferred from 'Jordan'\"\r\n"
				+ "  }, {\r\n"
				+ "    \"name\" : \"email\",\r\n"
				+ "    \"type\" : \"string\",\r\n"
				+ "    \"doc\" : \"Type inferred from 'ajordan0@com.com'\"\r\n"
				+ "  }, {\r\n"
				+ "    \"name\" : \"gender\",\r\n"
				+ "    \"type\" : \"string\",\r\n"
				+ "    \"doc\" : \"Type inferred from 'Female'\"\r\n"
				+ "  }, {\r\n"
				+ "    \"name\" : \"ip_address\",\r\n"
				+ "    \"type\" : \"string\",\r\n"
				+ "    \"doc\" : \"Type inferred from '1.197.201.2'\"\r\n"
				+ "  }, {\r\n"
				+ "    \"name\" : \"cc\",\r\n"
				+ "    \"type\" : [ \"null\", \"string\" ],\r\n"
				+ "    \"doc\" : \"Type inferred from '6759521864920116'\",\r\n"
				+ "    \"default\" : null\r\n"
				+ "  }, {\r\n"
				+ "    \"name\" : \"country\",\r\n"
				+ "    \"type\" : \"string\",\r\n"
				+ "    \"doc\" : \"Type inferred from 'Indonesia'\"\r\n"
				+ "  }, {\r\n"
				+ "    \"name\" : \"birthdate\",\r\n"
				+ "    \"type\" : \"string\",\r\n"
				+ "    \"doc\" : \"Type inferred from '3/8/1971'\"\r\n"
				+ "  }, {\r\n"
				+ "    \"name\" : \"salary\",\r\n"
				+ "    \"type\" : [ \"null\", \"string\" ],\r\n"
				+ "    \"doc\" : \"Type inferred from '49756.53'\",\r\n"
				+ "    \"default\" : null\r\n"
				+ "  }, {\r\n"
				+ "    \"name\" : \"title\",\r\n"
				+ "    \"type\" : \"string\",\r\n"
				+ "    \"doc\" : \"Type inferred from 'Internal Auditor'\"\r\n"
				+ "  }, {\r\n"
				+ "    \"name\" : \"comments\",\r\n"
				+ "    \"type\" : \"string\",\r\n"
				+ "    \"doc\" : \"Type inferred from '1E+02'\"\r\n"
				+ "  } ]\r\n"
				+ "}";
		
		Schema avroSchema = new Schema.Parser().parse(schemaStr);
		
		PCollection<GenericRecord> avroRecord = pipeline.apply(AvroIO.readGenericRecords(avroSchema).from("gs://apdh-avro-test/userdata1.avro"));
		
		PCollection<TableRow> bigQueryRows = avroRecord.apply(
		        MapElements.into(TypeDescriptor.of(TableRow.class))
		            .via(
		                (GenericRecord elem) ->
		                    new TableRow()
		                        .set("registration_dttm", String.valueOf(elem.get("registration_dttm")))
		                        .set("first_name", String.valueOf(elem.get("first_name")))
		                        .set("last_name", String.valueOf(elem.get("last_name")))
		                        .set("email", String.valueOf(elem.get("email")))
		                        .set("gender", String.valueOf(elem.get("gender")))
		                        .set("ip_address", String.valueOf(elem.get("ip_address")))
		                        .set("cc", String.valueOf(elem.get("cc")))
		                        .set("country", String.valueOf(elem.get("country")))
		                        .set("birthdate", String.valueOf(elem.get("birthdate")))
		                        .set("salary", String.valueOf(elem.get("salary")))
		                        .set("title", String.valueOf(elem.get("title")))
		                        .set("comments", String.valueOf(elem.get("comments")))
		                        .set("id", String.valueOf(elem.get("id")))));
		
		TableSchema bqSchema = new TableSchema().setFields(
				ImmutableList.of(
						new TableFieldSchema().setName("registration_dttm").setType("STRING"),
						new TableFieldSchema().setName("first_name").setType("STRING"),
						new TableFieldSchema().setName("last_name").setType("STRING"),
						new TableFieldSchema().setName("email").setType("STRING"),
						new TableFieldSchema().setName("gender").setType("STRING"),
						new TableFieldSchema().setName("ip_address").setType("STRING"),
						new TableFieldSchema().setName("cc").setType("STRING"),
						new TableFieldSchema().setName("country").setType("STRING"),
						new TableFieldSchema().setName("birthdate").setType("STRING"),
						new TableFieldSchema().setName("salary").setType("STRING"),
						new TableFieldSchema().setName("title").setType("STRING"),
						new TableFieldSchema().setName("comments").setType("STRING"),
						new TableFieldSchema().setName("id").setType("STRING")
						));
		
		PCollection<TableRow> tr = pipeline
				.apply(BigQueryIO.readTableRows().fromQuery("SELECT * FROM `jointest.avroresult`").usingStandardSql());
		
		JsonAvroConverter avroConverter = new JsonAvroConverter();
		Long l = 1L;
		Double d = (double) 1;
		JSONObject jsonObj = new JSONObject();
		jsonObj.put("registration_dttm", "M");
		jsonObj.put("first_name", "M");
		jsonObj.put("last_name", "M");
		jsonObj.put("email", "M");
		jsonObj.put("gender", "M");
		jsonObj.put("ip_address", "M");
		jsonObj.put("cc", "l");
		jsonObj.put("country", "M");
		jsonObj.put("birthdate", "M");
		jsonObj.put("salary", "d");
		jsonObj.put("title", "M");
		jsonObj.put("comments", "M");
		jsonObj.put("id", "l");
		GenericRecord record =
				avroConverter.convertToGenericDataRecord(jsonObj.toString().getBytes(), avroSchema);
		GenericRecord input = new GenericData.Record(avroSchema);
		
		input.put("registration_dttm", "M");
		input.put("first_name", "M");
		input.put("last_name", "M");
		input.put("email", "M");
		input.put("gender", "M");
		input.put("ip_address", "M");
		input.put("cc", "l");
		input.put("country", "M");
		input.put("birthdate", "M");
		input.put("salary", "d");
		input.put("title", "M");
		input.put("comments", "M");
		input.put("id", "l");
		
		
		//works GenericData.Record format for input
		//PCollection<Record> test = pipeline.apply(Create.of(record).withCoder(AvroCoder.of(GenericData.Record.class, avroSchema)));
		
		PCollection<GenericRecord> test = pipeline.apply(Create.of(record).withCoder(AvroCoder.of(GenericRecord.class, avroSchema)));
		PCollection<GenericRecord> check = tr.apply(ParDo.of(new ConvertTableRowToGenericRecordFn(avroSchema))).setCoder(AvroCoder.of(GenericRecord.class, avroSchema));
		check.apply("Write to avro test", AvroIO.writeGenericRecords(avroSchema)
				.to("gs://apdh-avro-test/newtest")
				.withoutSharding()
				.withSuffix(".avro"));
		
		PCollection<GenericRecord> newTest = pipeline.apply(Create.of(input).withCoder(AvroCoder.of(GenericRecord.class, avroSchema)));
		newTest.apply("Write to avro test", AvroIO.writeGenericRecords(avroSchema)
				.to("gs://apdh-avro-test/test")
				.withoutSharding()
				.withSuffix(".avro"));
		bigQueryRows.apply(BigQueryIO.writeTableRows()
				.to("jointest.avroresult")
				.withSchema(bqSchema)
				.withCreateDisposition(BigQueryIO.Write.CreateDisposition.CREATE_IF_NEEDED)
				.withWriteDisposition(BigQueryIO.Write.WriteDisposition.WRITE_TRUNCATE));
		pipeline.run(options).waitUntilFinish();
	}
	
	public static class ConvertTableRowToGenericRecordFn extends DoFn<TableRow, GenericRecord>{
		
		private final String avroSchemaStr;
		private Schema avroSchema;

		ConvertTableRowToGenericRecordFn(Schema avroSchema) {
			avroSchemaStr = String.valueOf(avroSchema);
		}
		
		@Setup
		public void Setup() {
			avroSchema = new Schema.Parser().parse(avroSchemaStr);
		}
		
		@ProcessElement
		public void ProcessElement(ProcessContext c) {
			TableRow obj = c.element().clone();
			
			GenericRecord output = new GenericData.Record(avroSchema);
			
			obj.entrySet().forEach((k)->{
				output.put(k.getKey(), k.getValue());
			});
			
			c.output(output);
		}
	}

	public static class ConvertToTableRow extends SimpleFunction<GenericRecord, TableRow>{
		
		
		private List<String> keys;

		public ConvertToTableRow(List<String> keys) {
			this.keys = keys;
		}
		
		public TableRow apply(GenericRecord input) {
			TableRow output = new TableRow();
			keys.stream().forEach((k)->{
				output.set(k, String.valueOf(input.get(k)));
			});
			return output;
		}
	}

}
